##  <font color="#8450B2">_Group: 3PM üëßüèªüë©üèªüë©üèºüë¶üèª_</font> <br>
Deep Learning ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏µ‡∏¢‡∏ô‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏Ç‡∏≠‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏ä‡∏±‡πâ‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ Layer ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤ Pattern ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 
‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏à‡∏∏‡∏î‡∏°‡∏∏‡πà‡∏á‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á **`Traditional Machine Learning (ML)`** ‡πÅ‡∏•‡∏∞ **`Multilayer Perceptron (MLP)`** ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£ tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö Hyperparameter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡∏°‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ô‡∏µ‡πâ 

## _Key Highlight_
- ‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏û‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ô‡∏ù‡∏±‡πà‡∏á‡∏Ç‡∏≠‡∏á Traditional ML ‡πÇ‡∏°‡πÄ‡∏î‡∏• RandomForestClassifier ‡πÉ‡∏´‡πâ Accuracy ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà 88.26% ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ó‡∏µ‡πà MLP ‡πÉ‡∏´‡πâ Accuracy ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà 84.93% ‡∏ã‡∏∂‡πà‡∏á‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏≤‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤
- ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏û‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ ReLu ‡πÄ‡∏õ‡πá‡∏ô activation function ‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô hidden ‡πÅ‡∏•‡∏∞ output layer ‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ error ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô batch ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏≠‡∏≤‡∏à‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏à‡∏≠‡∏Ñ‡πà‡∏≤ 0 ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏£‡∏≠‡∏ö‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡πà‡∏≤ backpropagation ‡πÅ‡∏•‡∏∞ error ‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏´‡∏≤‡∏Å‡πÉ‡∏ä‡πâ sigmoid ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß
- Dataset ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£ predict ‡∏Ñ‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢ MLP ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô Dataset ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ ‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡∏û‡∏≠‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏°‡∏≤‡∏Å‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô

## 1. Introduction
‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Stroke Prediction ‡πÇ‡∏î‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏õ‡πá‡∏ô **`Binary classification`** ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏Ñ‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏´‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏™‡∏°‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (1: ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏´‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏™‡∏°‡∏≠‡∏á, 0: ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏´‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏™‡∏°‡∏≠‡∏á) ‡∏ã‡∏∂‡πà‡∏á‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏≤‡∏¢‡∏∏, ‡πÄ‡∏û‡∏®, ‡πÇ‡∏£‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï‡∏™‡∏π‡∏á, ‡πÇ‡∏£‡∏Ñ‡∏´‡∏±‡∏ß‡πÉ‡∏à ‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡πÉ‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô

## 2. Data

### Data source
**Dataset descrption:**: Stroke Prediction Dataset (Ref: [Stroke Prediction Dataset | Kaggle](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset))))<br>
**Total Patient:** 5,110 <br>
**Total Features:** 11 <br>
**Fields:**
1) id: ‡∏£‡∏´‡∏±‡∏™‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢ 
2) gender: "Male", "Female" ‡∏´‡∏£‡∏∑‡∏≠ "Other"  
3) age: ‡∏≠‡∏≤‡∏¢‡∏∏‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢  
4) hypertension: 0 ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï‡∏™‡∏π‡∏á, 1 ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï‡∏™‡∏π‡∏á  
5) heart_disease: 0 ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏´‡∏±‡∏ß‡πÉ‡∏à, 1 ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏´‡∏±‡∏ß‡πÉ‡∏à
6) ever_married: "No" ‡∏´‡∏£‡∏∑‡∏≠ "Yes"  
7) work_type: "children", "Govt_jov", "Never_worked", "Private" ‡∏´‡∏£‡∏∑‡∏≠ "Self-employed"  
8) Residence_type: "Rural" ‡∏´‡∏£‡∏∑‡∏≠ "Urban"  
9) avg_glucose_level: ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡πÉ‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î  
10) bmi: ‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏°‡∏ß‡∏•‡∏Å‡∏≤‡∏¢
11) smoking_status: "formerly smoked", "never smoked", "smokes" ‡∏´‡∏£‡∏∑‡∏≠ "Unknown"*  
*Note: "Unknown" ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå smoking_status ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏£‡∏≤‡∏¢‡∏ô‡∏µ‡πâ* <br>

### EDA
![image](https://user-images.githubusercontent.com/101736826/189482360-ce111321-fce8-4679-952c-d6f820168e2c.png)
- ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à dataset ‡∏û‡∏ö‡∏ß‡πà‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏´‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏™‡∏°‡∏≠‡∏á‡πÇ‡∏î‡∏¢‡∏î‡∏π‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤ correlation ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ ‡∏≠‡∏≤‡∏¢‡∏∏ , Heart disease, Glucose Level
Hypertension, Married Status.

### Data preparation
‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô train model ‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ drop ‡∏Ñ‡πà‡∏≤ outliner ‡∏≠‡∏≠‡∏Å ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏∂‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Binary category ‡πÅ‡∏•‡∏∞ Multicategory ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **`One-Hot encoding`** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ categorical ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ Binary values ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Machine leaning ‡∏ô‡∏±‡πâ‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ train ‡πÅ‡∏•‡∏∞ predict ‡πÇ‡∏î‡∏¢‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå gender, ever_married, work_type, residence_type ‡πÅ‡∏•‡∏∞ smoking_status ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß <br>

‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏° imbalance ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ **`SMOTE`** (synthetic minority over-sampling technique) ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏°‡∏î‡∏∏‡∏•‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ normalize ‡∏Ñ‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢ StandardScaler <br>

‡πÅ‡∏•‡∏∞‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î 5,110 ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á Data splitting (train/val/test) ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ<br>
ML: Train 80% ‡πÅ‡∏•‡∏∞ Test 20%<br>
MLP: Train 80%, validation 20% ‡∏Ç‡∏≠‡∏á Train set ‡πÅ‡∏•‡∏∞ Test 20%<br>


![image](https://user-images.githubusercontent.com/101736826/187707794-38780d34-8cc0-4fd0-95de-48e3eda8c46f.png)

### Data Cleaning: 
‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ drop dataset 1 row ‡∏à‡∏≤‡∏Å 5,110 rows ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÉ‡∏ô Gender show "Other" ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÄ‡∏û‡∏®‡πÑ‡∏î‡πâ
### Data Transformation: 
  1. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Binary category ‡πÅ‡∏•‡∏∞ Multicategory ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **`One-Hot encoding`** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ categorical ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ Binary values ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Machine leaning ‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ train ‡πÅ‡∏•‡∏∞ predict ‡πÇ‡∏î‡∏¢‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå gender, ever_married <br>
  2. ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å dataset ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ class imbalance ‡∏à‡∏∂‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ **`SMOTE`** (synthetic minority over-sampling technique ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏°‡∏î‡∏∏‡∏•
  3. ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ normalize ‡∏Ñ‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢ StandardScaler ‡πÅ‡∏•‡∏∞ OneHotEncoding <br>

## 3. Network architecture
Total params: 7,354<br>
Trainable params: 7,354<br>
Non-trainable params: 0<br>
|Layer (type)|Output Shape|Number of Parameter|Activation function|
|------------|------------|-------------------|-------------------|
|hidden1 (Dense)|	(None, 89)|	801|	tanh|
|hidden2 (Dense)|	(None, 72)|	6,408|	tanh|
|dropout_1 (Dropout)| (None, 72)|	0|	-|
|output (Dense)|	(None, 1)|	73|	sigmoid|

## 4. Training
### 4.1 Traditional Machine Learning (ML)
‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ Scikit-learn ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô library ‡πÉ‡∏ô Python ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö Traditional Machine Learning ‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ **`RidgeClassifier`**, **`LinearSVC`**, **`SVC`**, **`LogisticRegression`**, **`KNeighborsClassifier`** , **`Xgboost`** ‡πÅ‡∏•‡∏∞ **`RandomForestClassifier`** <br>
‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ **`K-Fold Cross Validation`** ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 5 ‡∏£‡∏≠‡∏ö‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á accuracy ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞‡∏ô‡∏≥‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÑ‡∏õ‡∏õ‡∏£‡∏±‡∏ö‡∏´‡∏≤‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ **`Hyperparameter`** ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **`GridSearchCV`** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏±‡πâ‡∏ô‡πÜ <br>
‡πÇ‡∏î‡∏¢‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ model ‡∏°‡∏µ‡∏Å‡∏≤‡∏£ tuning ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ

- RidgeClassifier     : RidgeClassifier(alpha = 0.0001, solver = 'lsqr')
- LinearSVC           : LinearSVC(C= 0.001,multi_class = 'crammer_singer',penalty = 'l2',loss='hinge')
- SVC                 : SVC(C= 1.5, gamma = 'scale', kernel = 'rbf', random_state = 0)
- LogisticRegression  : LogisticRegression(C= 1, max_iter= 100,solver = 'sag', penalty = 'l2')
- KNeighborsClassifier: KNeighborsClassifier(n_neighbors=5, leaf_size = 10, weights='distance')
- Xgboost             : XGBClassifier(eval_metric= 'error', learning_rate=0.1)
- RandomForestClassifier: RandomForestClassifier(criterion= 'gini', random_state = 0, n_estimators= 100)

### 4.2 Multilayer Perceptron (MLP)
‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Multilayer Perceptron (MLP) ‡πÄ‡∏£‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ The Keras ecosystem (KerasTuner) ‡πÇ‡∏î‡∏¢‡∏à‡∏∞ trial-and-error ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏´‡∏≤ Hyperparamet ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏´‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏™‡∏°‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö dataset ‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô<br>
‡πÇ‡∏î‡∏¢‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ trial-and-error ‡∏°‡∏µ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ

|Hyperparameter	|List of value	|Best value for dataset|
|---------------|---------------|----------------------|
|Number of layer|[1,2,3]       	|3|
|Number of node	|[21, 22, ..., 100]	|89, 72|
|Learning rate	|[0.01, 0.001, 0.0001, 0.00001]	|ExponentialDecay <br>(itial_learning_rate=1e-2, <br> decay_steps=10000, <br> decay_rate=0.9)|
|Activation	    |[relu, tanh, sigmoid]	|tanh, sigmoid|
|Optimizer      |Adam          | Adam|
|Batch size     |-             |16|
|Epoch          |-             |100|
|Loss           |-             |binary_crossentropy|

## 5. Results
‡πÇ‡∏î‡∏¢‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠ 5.1 ‡πÅ‡∏•‡∏∞ 5.2 ‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å test set ‡∏ó‡∏±‡πâ‡∏á 2 ‡∏ï‡∏≤‡∏£‡∏≤‡∏á
### 5.1 Traditional Machine Learning (ML)

|Classification algorithm|	Accuracy|	Precision|	Recall	|F1|
|------------------------|----------|----------|----------|--|
|RandomForestüëè	|	88.26%|	25.93%|	14.89%|	18.92%|
|KNN|	82.68%	|40.74%|	13.17%|	19.91%|
|XGBClassifier	|76.32%|	57.41%|	12.40%|	20.39%|
|LogisticRegression	|75.83%|	70.37%|	14.13%|	23.53%|
|SVC|	75.24%	|72.22%|	14.08%|	23.57%|
|RidgeClassifier	|73.78%|	72.22%|	13.36%|	22.54%|
|LinearSVC	|72.31%|	77.78%|	13.41%|	22.89%|


### 5.2 Multilayer Perceptron (MLP)
‡πÇ‡∏î‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á Accuracy ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏ô‡∏±‡πâ‡∏ô ‡∏°‡∏≤‡∏Å‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á Accuracy ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏î‡πâ‡∏ß‡∏¢ initial random weights ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 5 ‡∏£‡∏≠‡∏ö <br>
‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ <br>
|CPU/GPU/TPU Name|Training Duration (MLP)|
|------------|------------|
|AMD Ryzen 7 4700U |6m|
|Google Colab: Tesla T4 |15m| 
|Google Colab: Tesla P100-PCIE-16GB|14m|  

‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏≤ Mean ‡πÅ‡∏•‡∏∞ SD ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ <br>
|round|Accuracy|Precision|Recall|F1|
|----|--------|----------|----|----|
|1|84.95% |46.30% |16.67% |24.51%|
|2|85.13% |40.74% |15.49% |22.45%|
|3|85.32% |44.44% |16.67% |24.24%|
|4|85.57% |46.30% |20.33% |28.25%|
|5|85.91% |46.30% |17.86% |25.77%|
|AVG|85.77% |44.81%|17.40%|25.04%|

<br>**Mean Accuracy of Test set:** 0.8577299412915853<br>
**STD:** 0.010709705121340223 <br>
**Mean¬±SD of Accuracy** = ( 0.8684396464129255 , 0.8470202361702451 )

#### ‡∏Å‡∏£‡∏≤‡∏ü‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ data train set vs. data test set
![image](https://user-images.githubusercontent.com/101736826/189178365-9b99fe9e-53bf-44fb-9ac9-915cee66bf19.png)
<br> ‡∏à‡∏≤‡∏Å‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤ ‡∏Ñ‡πà‡∏≤ accuracy ‡πÅ‡∏•‡∏∞ loss ‡∏Ç‡∏≠‡∏á validation ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏Å‡∏•‡πâ‡∏Ñ‡πà‡∏≤ train set ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• 500 epoch ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• goodfit
  

## 6.Discussion
- ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ train model ‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ model ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏° overfit ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏î‡∏π‡∏Ñ‡πà‡∏≤ correlation ‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏´‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏™‡∏°‡∏≠‡∏á (stroke) ‡∏ã‡∏∂‡πà‡∏á‡∏´‡∏≤‡∏Å correlation ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡∏Å ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô stroke ‡∏°‡∏≤‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏≤‡∏¢‡∏∏ ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏´‡∏±‡∏ß‡πÉ‡∏à ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô
- ‡∏Å‡∏≤‡∏£ normalization ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ StandardScaler ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Features ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏õ‡∏Å‡∏ï‡∏¥‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
- ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏•‡∏≠‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà imbalance ‡∏û‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡πà‡∏≤ accuracy ‡∏Ç‡∏≠‡∏á data train set ‡πÅ‡∏•‡∏∞ test set ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å (> 0.9) ‡πÅ‡∏ï‡πà‡∏Ñ‡πà‡∏≤ Precision, Recall ‡πÅ‡∏•‡∏∞ f1 ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏°‡∏≤‡∏Å (< 0.1) ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ **`SMOTE`** (synthetic minority over-sampling technique)
- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Stroke Prediction ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏° imbalance ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ SMOTE (synthetic minority over-sampling technique)  ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏à‡∏∞‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á Model ‡∏à‡∏£‡∏¥‡∏á<br>
‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train Set ‡∏°‡∏µ‡πÄ‡∏û‡∏µ‡∏¢‡∏á 195 instances ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô class1 (‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏´‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏™‡∏°‡∏≠‡∏á) ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ó‡∏µ‡πà class0 (‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏´‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏™‡∏°‡∏≠‡∏á) ‡∏°‡∏µ‡∏ñ‡∏∂‡∏á 3,892 instances<br>
‡∏à‡∏≤‡∏Å‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏ó‡∏≥‡πÉ‡∏´‡πâ Model ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏≤ Pattern ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á class1 ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏ô‡∏±‡∏Å ‡∏™‡πà‡∏á‡∏ú‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ Accuracy, Precision, Recall, F1 ‡∏Ç‡∏≠‡∏á class1 ‡∏ô‡πâ‡∏≠‡∏¢‡∏ï‡∏≤‡∏°‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢
- ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• MLP ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ tuning hyperparameter ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏≤‡∏Å ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏° ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å dataset ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏Å‡∏ô‡∏±‡∏Å ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ traditional ML ‡∏ã‡∏∂‡πà‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ tuning hyperparameter ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∂‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö dataset ‡∏ä‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤

## 7. Conclusion
- Dataset ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£ predict ‡∏Ñ‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢ MLP ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô Dataset ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ ‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡∏û‡∏≠‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏°‡∏≤‡∏Å‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô
- ‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏ö‡∏ß‡πà‡∏≤ RandomForestClassifier ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô traditional ML ‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ Accuracy ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà 0.8826 ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ó‡∏µ‡πà MLP ‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ Accuracy ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà 0.8577 ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    
|Performance<br>Measures|MLP|RandomForestüëè|KNN|XGBClassifier|LogisticRegression|
|-----------------------|---|------------|---|-------------|------------------|     
|1. Accuracy |85.77% |88.26% |82.68% |76.32% |75.83% |  
|2. Precision |85.77% |25.93% |40.74% |57.41% |70.37% |  
|3. Recall |17.40% |14.89% |13.17% |12.40% |14.13% |  
|4. F1 Score |25.04% |18.92% |19.91% |20.39% |23.53% |

## 8. References
- ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ automl ‡∏Ç‡∏≠‡∏á The Keras ecosystem: <br>
    **Authors:** Luca Invernizzi, James Long, Francois Chollet, Tom O'Malley, Haifeng Jin <br>
    **Last modified:** 2021/10/27 <br>
    **Link:** https://keras.io/guides/keras_tuner/getting_started/ <br>
    
- ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•: <br>
    **Authors:** SIDDHESH SAWANT <br>
    **Last modified:** 2021/03/26 <br>
    **Link:** https://www.kaggle.com/code/siddheshera/stroke-eda-smote-9-models-90-accuracy/comments <br>

    **Authors:** OHM-Songpol, nuijth, robinoud, MartRideratGamaGama <br>
    **Last modified:** 2022/02/07 <br>
    **Link:** https://github.com/robinoud/BADS7604_HW3_Deep-Learning
 
 - API Keras  ‡∏Ç‡∏≠‡∏á Tensorflow Libary <br>
    **Link:** https://www.tensorflow.org/api_docs/python/tf
    
 - ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏Å‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Dying ReLU <br>
    **Authors:** Kenneth Leung <br>
    **Last modified:** 2021/03/31 <br>
    **Link:** https://towardsdatascience.com/the-dying-relu-problem-clearly-explained-42d0c54e0d24
 
## _End Credit_

|Working Percentage|  ID |  Name | Details |
|------------------|-----|-------|---------|
|25% |6410422005     |Metpiya Learakkakorn|Prepare dataset, Data cleaning, EDA, ML, MLP, Report, Conclusion|    
|25% |6410422015     |Khodchapan Vitheethum |Prepare dataset, Data cleaning, EDA, ML, MLP, Report, Conclusion|
|25% |6410422017     |Peerat Pookpanich |Prepare dataset, Data cleaning, EDA, ML, MLP, Report, Conclusion|
|25% |6410422031     |Anyamanee Pornpanvattana |Prepare dataset, Data cleaning, EDA, ML, MLP, Report, Conclusion |

_‡∏á‡∏≤‡∏ô‡∏ä‡∏¥‡πâ‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á ‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡∏°‡∏´‡∏≤‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏û‡∏±‡∏í‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå_
